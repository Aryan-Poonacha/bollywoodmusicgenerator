{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#mixture of ideas and code from the following sources:\n",
    "#https://github.com/DebarghaG/Tansen/blob/master/train_network.py#L22\n",
    "#https://medium.com/@leesurkis/how-to-generate-techno-music-using-deep-learning-17c06910e1b3\n",
    "\n",
    "#most similar to this implementation:\n",
    "#https://hedonistrh.github.io/2018-04-27-Music-Generation-with-LSTM/\n",
    "\n",
    "#for parsing music\n",
    "import music21\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "#DL imports\n",
    "from keras import layers, models, Input\n",
    "from keras.models import Model\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.layers.advanced_activations import *\n",
    "\n",
    "#for sampling\n",
    "import random\n",
    "import sys\n",
    "\n",
    "#global variables; see below for actual hyperparam global vars\n",
    "\n",
    "#redundant\n",
    "#all_notes = {}\n",
    "#all_durations = {}\n",
    "#all_offsets = {}\n",
    "\n",
    "####################    HELPER FUNCTIONS    ###########################\n",
    "\n",
    "#from https://github.com/hedonistrh/bestekar/blob/master/LSTM_colab.ipynb\n",
    "def check_float(duration): # This function fix the issue which comes from some note's duration. \n",
    "                           # For instance some note has duration like 14/3 or 7/3. \n",
    "    if ('/' in duration):\n",
    "        numerator = float(duration.split('/')[0])\n",
    "        denominator = float(duration.split('/')[1])\n",
    "        duration = str(float(numerator/denominator))\n",
    "    return duration\n",
    "\n",
    "#from https://github.com/hedonistrh/bestekar/blob/master/LSTM_colab.ipynb\n",
    "def note_to_int(note): # converts the note's letter to pitch value which is integer form.\n",
    "    # source: https://musescore.org/en/plugin-development/note-pitch-values\n",
    "    # idea: https://github.com/bspaans/python-mingus/blob/master/mingus/core/notes.py\n",
    "    \n",
    "    note_base_name = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
    "    if ('#-' in note):\n",
    "        first_letter = note[0]\n",
    "        base_value = note_base_name.index(first_letter)\n",
    "        octave = note[3]\n",
    "        value = base_value + 12*(int(octave)-(-1))\n",
    "        \n",
    "    elif ('#' in note): \n",
    "        first_letter = note[0]\n",
    "        base_value = note_base_name.index(first_letter)\n",
    "        octave = note[2]\n",
    "        value = base_value + 12*(int(octave)-(-1))\n",
    "        \n",
    "    elif ('-' in note): \n",
    "        first_letter = note[0]\n",
    "        base_value = note_base_name.index(first_letter)\n",
    "        octave = note[2]\n",
    "        value = base_value + 12*(int(octave)-(-1))\n",
    "        \n",
    "    else:\n",
    "        first_letter = note[0]\n",
    "        base_val = note_base_name.index(first_letter)\n",
    "        octave = note[1]\n",
    "        value = base_val + 12*(int(octave)-(-1))\n",
    "        \n",
    "    return value\n",
    "\n",
    "\n",
    "#function from https://github.com/hedonistrh/bestekar/blob/master/LSTM_colab.ipynb generalised to extract the chords, notes and offsets of any instrument for given midi file\n",
    "def extract_instrument_features(instrument_index, parts):\n",
    "    notes_to_parse = parts.parts[instrument_index].recurse()\n",
    "    duration_instrument = float(check_float((str(notes_to_parse._getDuration()).split(' ')[-1])[:-1]))\n",
    "            \n",
    "    durations = []\n",
    "    notes = []\n",
    "    offsets = []\n",
    "            \n",
    "    for element in notes_to_parse:\n",
    "        if isinstance(element, music21.note.Note): # If it is single note\n",
    "            notes.append(note_to_int(str(element.pitch))) # Append note's integer value to \"notes\" list.\n",
    "            duration = str(element.duration)[27:-1] \n",
    "            durations.append(check_float(duration)) \n",
    "            offsets.append(element.offset)\n",
    "\n",
    "        elif isinstance(element, music21.chord.Chord): # If it is chord\n",
    "            notes.append('.'.join(str(note_to_int(str(n)))\n",
    "                                    for n in element.pitches))\n",
    "            duration = str(element.duration)[27:-1]\n",
    "            durations.append(check_float(duration))\n",
    "            offsets.append(element.offset)\n",
    "                    \n",
    "    return durations, notes, offsets\n",
    "    \n",
    "def check_float(duration): # This function fix the issue which comes from some note's duration. \n",
    "                           # For instance some note has duration like 14/3 or 7/3. \n",
    "    if ('/' in duration):\n",
    "        numerator = float(duration.split('/')[0])\n",
    "        denominator = float(duration.split('/')[1])\n",
    "        duration = str(float(numerator/denominator))\n",
    "    return duration\n",
    "\n",
    "\n",
    "#postprocessing sampler for generated audio\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    \n",
    "    num_of_top = 15\n",
    "    num_of_first = np.random.randint(1,3)\n",
    "\n",
    "    \n",
    "    preds [0:48] = 0 # eliminate notes with low octaves\n",
    "    preds [100:] = 0 # eliminate notes with very high octaves\n",
    "    \n",
    "    ind = np.argpartition(preds, -1*num_of_top)[-1*num_of_top:]\n",
    "    top_indices_sorted = ind[np.argsort(preds[ind])]\n",
    "    \n",
    "    \n",
    "    array = np.random.uniform(0.0, 0.0, (128)) \n",
    "    array[top_indices_sorted[0:num_of_first]] = 1.0\n",
    "    array[top_indices_sorted[num_of_first:num_of_first+3]] = 0.5\n",
    "\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS FUNCTION DEALS WITH HOW THE EXTRACTED FEATURES ARE CONVERTED INTO THE INPUT VECTOR FOR THE RNN\n",
    "\n",
    "#TAKEN FROM: https://github.com/hedonistrh/bestekar/blob/master/LSTM_colab.ipynb\n",
    "\n",
    "# Lets determine our matrix's value \n",
    "# rest --> (min_value, lower_bound)\n",
    "# continuation --> (lower_bound, upper_bound)\n",
    "# first_touch --> (upper_bound, max_value)\n",
    "\n",
    "min_value = 0.00\n",
    "lower_first = 0.00\n",
    "\n",
    "lower_second = 0.5\n",
    "upper_first = 0.5\n",
    "\n",
    "upper_second = 1.0\n",
    "max_value = 1.0\n",
    "\n",
    "#taken from https://github.com/hedonistrh/bestekar/blob/master/LSTM_colab.ipynb\n",
    "def notes_to_matrix(notes, durations, offsets, min_value=min_value, lower_first=lower_first,\n",
    "                    lower_second=lower_second,\n",
    "                    upper_first=upper_first, upper_second=upper_second,\n",
    "                    max_value=max_value):\n",
    "    \n",
    "    # I want to represent my notes in matrix form. X axis will represent time, Y axis will represent pitch values.\n",
    "    # I should normalize my matrix between 0 and 1.\n",
    "    # So that I will represent rest with (min_value, lower_first), continuation with [lower_second, upper_first]\n",
    "    # and first touch with (upper_second, max_value)\n",
    "    # First touch means that you press the note and it cause to 1 time duration playing. Continuation\n",
    "    # represent the continuum of this note playing. \n",
    "    \n",
    "    try:\n",
    "        last_offset = int(offsets[-1]) \n",
    "    except IndexError:\n",
    "        print ('Index Error')\n",
    "        return (None, None, None)\n",
    "    \n",
    "    total_offset_axis = last_offset * 4 + (8 * 4) \n",
    "    our_matrix = np.random.uniform(min_value, lower_first, (128, int(total_offset_axis))) \n",
    "    # creates matrix and fills with (-1, -0.3), this values will represent the rest.\n",
    "    \n",
    "    for (note, duration, offset) in zip(notes, durations, offsets):\n",
    "        how_many = int(float(duration)/0.25) # indicates time duration for single note.\n",
    "       \n",
    "        \n",
    "        # Define difference between single and double note.\n",
    "        # I have choose the value for first touch, the another value for continuation.\n",
    "        # Lets make it randomize\n",
    "        \n",
    "        # I choose to use uniform distrubition. Maybe, you can use another distrubition like Gaussian.\n",
    "        # I will try \n",
    "        first_touch = np.random.uniform(upper_second, max_value, 1)\n",
    "        continuation = np.random.uniform(lower_second, upper_first, 1)\n",
    "        \n",
    "        if ('.' not in str(note)): # It is not chord. Single note.\n",
    "            our_matrix[note, int(offset * 4)] = first_touch\n",
    "            our_matrix[note, int((offset * 4) + 1) : int((offset * 4) + how_many)] = continuation\n",
    "\n",
    "        else: # For chord\n",
    "            chord_notes_str = [note for note in note.split('.')] \n",
    "            chord_notes_float = list(map(int, chord_notes_str)) # Take notes in chord one by one\n",
    "\n",
    "            for chord_note_float in chord_notes_float:\n",
    "                our_matrix[chord_note_float, int(offset * 4)] = first_touch\n",
    "                our_matrix[chord_note_float, int((offset * 4) + 1) : int((offset * 4) + how_many)] = continuation\n",
    "                \n",
    "    return our_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#ITERATE THROUGH ALL MIDI FILES IN /data DIR AND CONVERT THEM INTO MATRICES OF UNIFORM SHAPE TO FEED INTO RNN\n",
    "\n",
    "def parse_music_dominant_instrument(directory = 'data', length = 250):\n",
    "    \n",
    "    input_matrices = []\n",
    "    \n",
    "    for file in os.listdir(directory):\n",
    "        \n",
    "        print('\\n')\n",
    "        print('parsing ' + file + '...')\n",
    "        midi_file = music21.converter.parse(directory + '/' + file)\n",
    "        \n",
    "        notes_to_parse = None\n",
    "        \n",
    "        #partition by instrument\n",
    "        parts = music21.instrument.partitionByInstrument(midi_file)\n",
    "        \n",
    "        instrument_names = []\n",
    "        \n",
    "        try:\n",
    "            for instrument in parts: # Learn names of instruments.\n",
    "                name = (str(instrument).split(' ')[-1])[:-1]\n",
    "                instrument_names.append(name)\n",
    "            print('Instruments in ' + file + ':')\n",
    "            print(instrument_names)\n",
    "\n",
    "        except TypeError:\n",
    "            print ('Type is not iterable for ' + file)\n",
    "            continue #can't iterate over instruments for this midi file; go to next file\n",
    "        \n",
    "        #identify and extract the features of the most dominant instrument\n",
    "        dominant_instrument_name = ''\n",
    "        for instrument_name in instrument_names:\n",
    "            dominant_instrument_name = instrument_name\n",
    "            instrument_index = instrument_names.index(instrument_name)\n",
    "            instrument_durations, instrument_notes, instrument_offsets = extract_instrument_features(instrument_index, parts)\n",
    "            if instrument_durations and instrument_notes and instrument_offsets:\n",
    "                break\n",
    "        \n",
    "        #redundant\n",
    "        #all_durations[file] = instrument_durations\n",
    "        #all_notes[file] = instrument_notes\n",
    "        #all_offsets[file] = instrument_offsets\n",
    "        \n",
    "        print('The Dominant instrument of ' + file + ' is :' + dominant_instrument_name)\n",
    "        print('Instrument Durations Length: ' + str(len(instrument_durations)))\n",
    "        print('Instrument Notes Length: ' + str(len(instrument_notes)))\n",
    "        print('Instrument Offsets Length: ' + str(len(instrument_offsets)))\n",
    "        \n",
    "        '''\n",
    "        print('Instrument Durations: ')\n",
    "        print(instrument_durations)\n",
    "        print('Instrument Notes: ')\n",
    "        print(instrument_notes)\n",
    "        print('Instrument Offsets: ')\n",
    "        print(instrument_offsets)\n",
    "        '''\n",
    "        \n",
    "        our_matrix = notes_to_matrix(instrument_notes, instrument_durations, instrument_offsets)\n",
    "    \n",
    "        try:\n",
    "            freq, time = our_matrix.shape\n",
    "        except AttributeError:\n",
    "            print(\"'tuple' object has no attribute 'shape'. Trouble converting notes to matrix and moving to next file.\")\n",
    "            continue\n",
    "\n",
    "        if (time >= length):\n",
    "            input_matrices.append(our_matrix[:,:length]) # We have to set all individual note matrix to same shape for Generative DL.\n",
    "        else:\n",
    "            print(file + ' is not of long enough duration to be used as a part of the training set.')\n",
    "    \n",
    "    return input_matrices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ITERATE THROUGH ALL MIDI FILES IN /data DIR AND CONVERT THEM INTO MATRICES OF UNIFORM SHAPE TO FEED INTO RNN\n",
    "\n",
    "def parse_music_all_instruments(directory = 'data', length = 250):\n",
    "    \n",
    "    input_matrices = []\n",
    "    \n",
    "    for file in os.listdir(directory):\n",
    "        \n",
    "        print('\\n')\n",
    "        print('parsing ' + file + '...')\n",
    "        midi_file = music21.converter.parse(directory + '/' + file)\n",
    "        \n",
    "        notes_to_parse = None\n",
    "        \n",
    "        #partition by instrument\n",
    "        parts = music21.instrument.partitionByInstrument(midi_file)\n",
    "        \n",
    "        instrument_names = []\n",
    "        \n",
    "        try:\n",
    "            for instrument in parts: # Learn names of instruments.\n",
    "                name = (str(instrument).split(' ')[-1])[:-1]\n",
    "                instrument_names.append(name)\n",
    "            print('Instruments in ' + file + ':')\n",
    "            print(instrument_names)\n",
    "\n",
    "        except TypeError:\n",
    "            print ('Type is not iterable for ' + file)\n",
    "            continue #can't iterate over instruments for this midi file; go to next file\n",
    "        \n",
    "        #identify and extract the features of the most dominant instrument\n",
    "        dominant_instrument_name = ''\n",
    "        for instrument_name in instrument_names:\n",
    "            dominant_instrument_name = instrument_name\n",
    "            instrument_index = instrument_names.index(instrument_name)\n",
    "            instrument_durations, instrument_notes, instrument_offsets = extract_instrument_features(instrument_index, parts)\n",
    "            \n",
    "            if len(instrument_durations)>=5 and len(instrument_notes)>=5 and len(instrument_offsets)>=5:\n",
    "            #if len(instrument_durations) and len(instrument_notes) and len(instrument_offsets):\n",
    "                \n",
    "                print('The next found instrument of ' + file + ' is :' + dominant_instrument_name)\n",
    "                print('Instrument Durations Length: ' + str(len(instrument_durations)))\n",
    "                print('Instrument Notes Length: ' + str(len(instrument_notes)))\n",
    "                print('Instrument Offsets Length: ' + str(len(instrument_offsets)))\n",
    "        \n",
    "                our_matrix = notes_to_matrix(instrument_notes, instrument_durations, instrument_offsets)\n",
    "    \n",
    "                try:\n",
    "                    freq, time = our_matrix.shape\n",
    "                except AttributeError:\n",
    "                    print(\"'tuple' object has no attribute 'shape'. Trouble converting notes to matrix and moving to next instrument of this file.\")\n",
    "                    continue\n",
    "\n",
    "                if (time >= length):\n",
    "                    input_matrices.append(our_matrix[:,:length]) # We have to set all individual note matrix to same shape for Generative DL.\n",
    "                else:\n",
    "                    print(dominant_instrument_name + ' is not of long enough duration to be used as a part of the training set.')\n",
    "    \n",
    "    return input_matrices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates the actual input and real output X and Y to be passed to Keras's model.fit(X,y) from the parsed matrices created by parse_music()\n",
    "#X is just the notes inscribed with the durations+offsets; Y is the same, but the future predictions stepped to the right by 'step'\n",
    "#max_len is the number of X time lengths used to predict a given Y\n",
    "#max_len and step are hyperparams; can use for tuning later\n",
    "#wrapped into a function using code from https://github.com/hedonistrh/bestekar/blob/master/LSTM_colab.ipynb\n",
    "\n",
    "def create_training_data(input_matrices, max_len = 15, step = 1):\n",
    "    \n",
    "    midis_array = np.asarray(input_matrices)\n",
    "    midis_array_raw = midis_array\n",
    "    \n",
    "    \n",
    "    # Midis array shape --> (# of file, # of frx.eq, # of time in a single file)\n",
    "    # Firtly, I will convert to (# of file, # of time in a single file, # of freq,)\n",
    "    midis_array = np.transpose(midis_array_raw, (0, 2, 1)) \n",
    "    midis_array = np.asarray(midis_array)\n",
    "    \n",
    "    # Secondly, convert to (# of freq, # of file * # of time in a single file)\n",
    "    midis_array = np.reshape(midis_array,(-1,128))\n",
    "    \n",
    "    print(midis_array.shape)\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for i in range (0, midis_array.shape[0]-max_len, step):\n",
    "        prev = midis_array[i:i+max_len,...] # take max_len column.\n",
    "        pred = midis_array[i+max_len,...] # take (max_len)th column.\n",
    "        X.append(prev)\n",
    "        Y.append(pred)\n",
    "    \n",
    "    #convert lists to np arrays\n",
    "    X = np.asarray(X).astype('float64')\n",
    "    Y = np.asarray(Y).astype('float64')\n",
    "    \n",
    "    return X,Y, midis_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reverse funcs to convert sampled matrices data back into midi format\n",
    "\n",
    "def int_to_note(integer):\n",
    "    # Convert pitch value to the note which is a letter form. \n",
    "    note_base_name = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
    "    octave_detector = (integer // 12) \n",
    "    base_name_detector = (integer % 12) \n",
    "    note = note_base_name[base_name_detector] + str((int(octave_detector))-1)\n",
    "    if ('-' in note):\n",
    "        note = note_base_name[base_name_detector] + str(0)\n",
    "        return note\n",
    "    return note\n",
    "\n",
    "# PAY ATTENTION. From matrix form to midi form, I have to indicate first touch, continuation and rest with unique numbers.\n",
    "# I choose -1.0 for rest , 0 for continuation and 1 for first touch.\n",
    "\n",
    "lower_bound = (lower_first + lower_second) / 2\n",
    "upper_bound = (upper_first + upper_second) / 2\n",
    "\n",
    "def converter_func(arr,first_touch = 1.0, continuation = 0.0, lower_bound = lower_bound, upper_bound = upper_bound):\n",
    "    # I can write this function thanks to https://stackoverflow.com/questions/16343752/numpy-where-function-multiple-conditions\n",
    "    # First touch represent start for note, continuation represent continuation for first touch, 0 represent end or rest\n",
    "    np.place(arr, arr < lower_bound, -1.0)\n",
    "    np.place(arr, (lower_bound <= arr) & (arr < upper_bound), 0.0)\n",
    "    np.place(arr, arr >= upper_bound, 1.0)\n",
    "    return arr\n",
    "\n",
    "def how_many_repetitive_func(array, from_where=0, continuation=0.0):\n",
    "    new_array = array[from_where:]\n",
    "    count_repetitive = 1 \n",
    "    for i in new_array:\n",
    "        if (i != continuation):\n",
    "            return (count_repetitive)\n",
    "        else:\n",
    "            count_repetitive += 1\n",
    "    return (count_repetitive)\n",
    "\n",
    "def matrix_to_midi(matrix, random=0):\n",
    "    first_touch = 1.0\n",
    "    continuation = 0.0\n",
    "    y_axis, x_axis = matrix.shape\n",
    "    output_notes = []\n",
    "    offset = 0\n",
    "        \n",
    "    # Delete rows until the row which include 'first_touch'\n",
    "    how_many_in_start_zeros = 0\n",
    "    for x_axis_num in range(x_axis):\n",
    "        one_time_interval = matrix[:,x_axis_num] # Values in a column.\n",
    "        one_time_interval_norm = converter_func(one_time_interval)\n",
    "        if (first_touch not in one_time_interval_norm):\n",
    "            how_many_in_start_zeros += 1\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    how_many_in_end_zeros = 0\n",
    "    for x_axis_num in range(x_axis-1,0,-1):\n",
    "        one_time_interval = matrix[:,x_axis_num] # values in a column\n",
    "        one_time_interval_norm = converter_func(one_time_interval)\n",
    "        if (first_touch not in one_time_interval_norm):\n",
    "            how_many_in_end_zeros += 1\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    print ('How many rows for non-start note at beginning:', how_many_in_start_zeros)\n",
    "    print ('How many rows for non-start note at end:', how_many_in_end_zeros)\n",
    "\n",
    "    matrix = matrix[:,how_many_in_start_zeros:]\n",
    "    y_axis, x_axis = matrix.shape\n",
    "    print (y_axis, x_axis)\n",
    "\n",
    "    for y_axis_num in range(y_axis):\n",
    "        one_freq_interval = matrix[y_axis_num,:] # Values in a row.\n",
    "        \n",
    "        one_freq_interval_norm = converter_func(one_freq_interval)\n",
    "        \n",
    "        i = 0        \n",
    "        offset = 0\n",
    "        \n",
    "        if (random):\n",
    "          \n",
    "          while (i < len(one_freq_interval)):\n",
    "                how_many_repetitive = 0\n",
    "                temp_i = i\n",
    "                if (one_freq_interval_norm[i] == first_touch):\n",
    "                    how_many_repetitive = how_many_repetitive_func(one_freq_interval_norm, from_where=i+1, continuation=continuation)\n",
    "                    i += how_many_repetitive \n",
    "\n",
    "                if (how_many_repetitive > 0):\n",
    "                    random_num = np.random.randint(3,6)\n",
    "                    new_note = music21.note.Note(int_to_note(y_axis_num),duration=music21.duration.Duration(0.25*random_num*how_many_repetitive))\n",
    "                    new_note.offset = 0.25*temp_i*2\n",
    "                    new_note.storedInstrument = music21.instrument.Piano()\n",
    "                    output_notes.append(new_note)\n",
    "                else:\n",
    "                    i += 1\n",
    "        \n",
    "          \n",
    "        else:\n",
    "          \n",
    "          while (i < len(one_freq_interval)):\n",
    "                how_many_repetitive = 0\n",
    "                temp_i = i\n",
    "                if (one_freq_interval_norm[i] == first_touch):\n",
    "                    how_many_repetitive = how_many_repetitive_func(one_freq_interval_norm, from_where=i+1, continuation=continuation)\n",
    "                    i += how_many_repetitive \n",
    "\n",
    "                if (how_many_repetitive > 0):\n",
    "                    new_note = music21.note.Note(int_to_note(y_axis_num),duration=music21.duration.Duration(0.25*how_many_repetitive))\n",
    "                    new_note.offset = 0.25*temp_i\n",
    "                    new_note.storedInstrument = music21.instrument.Piano()\n",
    "                    output_notes.append(new_note)\n",
    "                else:\n",
    "                    i += 1\n",
    "        \n",
    "    return output_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the actual RNN model wrapped into a function. Taken from https://github.com/hedonistrh/bestekar/blob/master/LSTM_colab.ipynb\n",
    "\n",
    "#v0: original version from https://github.com/hedonistrh/bestekar/blob/master/LSTM_colab.ipynb\n",
    "#v2: all layers except \n",
    "\n",
    "def RNN_model(max_len, no_of_values):\n",
    "    \n",
    "    input_midi = keras.Input((max_len, no_of_values))\n",
    "    \n",
    "    #LSTM 1 is halved for v3 from 1024 to 512\n",
    "    x = layers.Bidirectional(layers.LSTM(512, return_sequences=True, unit_forget_bias=True))(input_midi)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    x = layers.BatchNormalization() (x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    # compute importance/attention for each step\n",
    "    attention = layers.Dense(1, activation='tanh')(x)\n",
    "    attention = layers.Flatten()(attention)\n",
    "    attention = layers.Activation('softmax')(attention)\n",
    "    #copy layer 1 is halved for v3 from 1024 to 512\n",
    "    attention = layers.RepeatVector(1024)(attention)\n",
    "    attention = layers.Permute([2, 1])(attention)\n",
    "\n",
    "    multiplied = layers.Multiply()([x, attention])\n",
    "    sent_representation = layers.Dense(512)(multiplied)\n",
    "\n",
    "    #halved from 512 to 256 for v2 and v3\n",
    "    x = layers.Dense(256)(sent_representation)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    x = layers.BatchNormalization() (x)\n",
    "    x = layers.Dropout(0.22)(x)\n",
    "\n",
    "    #halved from 512 to 256 for v2 and v3\n",
    "    x = layers.Bidirectional(layers.LSTM(256, return_sequences=True, unit_forget_bias=True))(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    x = layers.BatchNormalization() (x)\n",
    "    x = layers.Dropout(0.22)(x)\n",
    "\n",
    "\n",
    "    # compute importance for each step\n",
    "    attention = layers.Dense(1, activation='tanh')(x)\n",
    "    attention = layers.Flatten()(attention)\n",
    "    attention = layers.Activation('softmax')(attention)\n",
    "    #halved from 512 to 256 for v2 and v3\n",
    "    attention = layers.RepeatVector(512)(attention)\n",
    "    attention = layers.Permute([2, 1])(attention)\n",
    "\n",
    "    multiplied = layers.Multiply()([x, attention])\n",
    "    #halved from 256 to 128 for v2 and v3\n",
    "    sent_representation = layers.Dense(128)(multiplied)\n",
    "\n",
    "    #halved from 256 to 128 for v2 and v3\n",
    "    x = layers.Dense(128)(sent_representation)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    x = layers.BatchNormalization() (x)\n",
    "    x = layers.Dropout(0.22)(x)\n",
    "\n",
    "    #lowest possible value of 128 for all versions\n",
    "    x = layers.LSTM(128, unit_forget_bias=True)(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    x = layers.BatchNormalization() (x)\n",
    "    x = layers.Dropout(0.22)(x)\n",
    "\n",
    "    #lowest possible value of 128 for all versions\n",
    "    x = layers.Dense(128, activation='softmax')(x) \n",
    "\n",
    "    model = Model(inputs = input_midi, outputs = x)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#GLOBAL VAR HYPERPARAMS\n",
    "\n",
    "max_len = 20\n",
    "step = 1\n",
    "no_of_values = 128 #the total number of kinds of notes; has been 128 throughout. Not really a hyperparam, fixed for no of notes\n",
    "no_of_epochs = 28\n",
    "batch_size = 4\n",
    "alpha = 0.0001\n",
    "length = 250\n",
    "\n",
    "directory = 'All Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse midi data into matrices\n",
    "matrices = parse_music_all_instruments(directory, length)\n",
    "print(len(matrices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving this data for later by pickleing\n",
    "var_to_save = matrices\n",
    "var_name = 'all_data_all_instruments_matrices'\n",
    "\n",
    "with open(var_name, 'wb') as fp:\n",
    "    pickle.dump(var_to_save, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open previously saved data\n",
    "file_name = 'all_data_all_instruments_matrices'\n",
    "\n",
    "with open (file_name, 'rb') as fp:\n",
    "    openedvar = pickle.load(fp)\n",
    "\n",
    "matrices = openedvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64000, 128)\n",
      "(63980, 20, 128)\n",
      "(63980, 128)\n"
     ]
    }
   ],
   "source": [
    "#convert parsed data into training data format\n",
    "Xtrain, Ytrain, midis_array = create_training_data(matrices, max_len, step = 1)\n",
    "print(Xtrain.shape)\n",
    "print(Ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 20, 128)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 20, 1024)     2625536     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 20, 1024)     0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 20, 1024)     4096        leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 20, 1024)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 20, 1)        1025        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 20)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 20)           0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 1024, 20)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 20, 1024)     0           repeat_vector_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 20, 1024)     0           dropout_1[0][0]                  \n",
      "                                                                 permute_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 20, 512)      524800      multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 20, 256)      131328      dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 20, 256)      0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 20, 256)      1024        leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 20, 256)      0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 20, 512)      1050624     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 20, 512)      0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 20, 512)      2048        leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 20, 512)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 20, 1)        513         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 20)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 20)           0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_2 (RepeatVector)  (None, 512, 20)      0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_2 (Permute)             (None, 20, 512)      0           repeat_vector_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 20, 512)      0           dropout_3[0][0]                  \n",
      "                                                                 permute_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 20, 128)      65664       multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 20, 128)      16512       dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 20, 128)      0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 20, 128)      512         leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 20, 128)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 128)          131584      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 128)          0           lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128)          512         leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 128)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 128)          16512       dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,572,290\n",
      "Trainable params: 4,568,194\n",
      "Non-trainable params: 4,096\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#create model instance\n",
    "model = RNN_model(max_len, no_of_values)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose optimiser and compile\n",
    "#from https://github.com/hedonistrh/bestekar/blob/master/LSTM_colab.ipynb\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=alpha, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=0.0, amsgrad=False)\n",
    "# optimizer = keras.optimizers.Nadam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-8, schedule_decay=0.004)\n",
    "#optimizer = keras.optimizers.SGD(lr=0.007)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open a previously saved full model; use this to continue training\n",
    "model = keras.models.load_model('model_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Epoch 1/1\n",
      "63980/63980 [==============================] - 1172s 18ms/step - loss: 3.9004\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 20\n",
      "How many rows for non-start note at end: 0\n",
      "128 480\n",
      "Epoch: 2\n",
      "Epoch 1/1\n",
      "63980/63980 [==============================] - 1181s 18ms/step - loss: 4.1034\n",
      "Epoch: 3\n",
      "Epoch 1/1\n",
      "63980/63980 [==============================] - 1194s 19ms/step - loss: 4.1888\n",
      "Epoch: 4\n",
      "Epoch 1/1\n",
      "63980/63980 [==============================] - 1189s 19ms/step - loss: 4.0126\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 500\n",
      "Epoch: 5\n",
      "Epoch 1/1\n",
      "63980/63980 [==============================] - 1192s 19ms/step - loss: 3.7785\n",
      "Epoch: 6\n",
      "Epoch 1/1\n",
      "63980/63980 [==============================] - 1197s 19ms/step - loss: 3.6259\n",
      "Epoch: 7\n",
      "Epoch 1/1\n",
      "63980/63980 [==============================] - 1197s 19ms/step - loss: 3.5493\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 500\n",
      "Epoch: 8\n",
      "Epoch 1/1\n",
      "63980/63980 [==============================] - 1196s 19ms/step - loss: 3.5359\n",
      "Epoch: 9\n",
      "Epoch 1/1\n",
      "63980/63980 [==============================] - 1196s 19ms/step - loss: 3.5352\n",
      "Epoch: 10\n",
      "Epoch 1/1\n",
      "63980/63980 [==============================] - 1195s 19ms/step - loss: 3.5439\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 18\n",
      "How many rows for non-start note at end: 0\n",
      "128 482\n",
      "Epoch: 11\n",
      "Epoch 1/1\n",
      "63980/63980 [==============================] - 1195s 19ms/step - loss: 3.5742\n",
      "Epoch: 12\n",
      "Epoch 1/1\n",
      "63980/63980 [==============================] - 1195s 19ms/step - loss: 3.5961\n",
      "Epoch: 13\n",
      "Epoch 1/1\n",
      "63980/63980 [==============================] - 1195s 19ms/step - loss: 3.6463\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 20\n",
      "How many rows for non-start note at end: 0\n",
      "128 480\n",
      "Epoch: 14\n",
      "Epoch 1/1\n",
      "63980/63980 [==============================] - 1195s 19ms/step - loss: 3.6884\n",
      "Epoch: 15\n",
      "Epoch 1/1\n",
      "63980/63980 [==============================] - 1196s 19ms/step - loss: 3.7323\n",
      "Epoch: 16\n",
      "Epoch 1/1\n",
      "63980/63980 [==============================] - 1196s 19ms/step - loss: 3.7728\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 500\n",
      "Epoch: 17\n",
      "Epoch 1/1\n",
      "63980/63980 [==============================] - 1194s 19ms/step - loss: 3.8092\n",
      "Epoch: 18\n",
      "Epoch 1/1\n",
      "63980/63980 [==============================] - 1195s 19ms/step - loss: 3.8395\n",
      "Epoch: 19\n",
      "Epoch 1/1\n",
      "63980/63980 [==============================] - 1195s 19ms/step - loss: 3.9040\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 20\n",
      "How many rows for non-start note at end: 0\n",
      "128 480\n",
      "Epoch: 20\n",
      "Epoch 1/1\n",
      "63980/63980 [==============================] - 1195s 19ms/step - loss: 3.9423\n",
      "Epoch: 21\n",
      "Epoch 1/1\n",
      "63980/63980 [==============================] - 1195s 19ms/step - loss: 3.9724\n",
      "Epoch: 22\n",
      "Epoch 1/1\n",
      "63980/63980 [==============================] - 1196s 19ms/step - loss: 4.0245\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 20\n",
      "How many rows for non-start note at end: 0\n",
      "128 480\n",
      "Epoch: 23\n",
      "Epoch 1/1\n",
      "63980/63980 [==============================] - 1195s 19ms/step - loss: 4.0530\n",
      "Epoch: 24\n",
      "Epoch 1/1\n",
      "63980/63980 [==============================] - 1196s 19ms/step - loss: 4.1011\n",
      "Epoch: 25\n",
      "Epoch 1/1\n",
      "63980/63980 [==============================] - 1198s 19ms/step - loss: 4.1610\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 20\n",
      "How many rows for non-start note at end: 0\n",
      "128 480\n",
      "Epoch: 26\n",
      "Epoch 1/1\n",
      "63980/63980 [==============================] - 1196s 19ms/step - loss: 4.2250\n",
      "Epoch: 27\n",
      "Epoch 1/1\n",
      "63980/63980 [==============================] - 1211s 19ms/step - loss: 4.2316\n",
      "Epoch: 28\n",
      "Epoch 1/1\n",
      "63980/63980 [==============================] - 1185s 19ms/step - loss: 4.2805\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 20\n",
      "How many rows for non-start note at end: 0\n",
      "128 480\n"
     ]
    }
   ],
   "source": [
    "#train the model and produce eg. samples after every few epochs\n",
    "\n",
    "for epoch in range(no_of_epochs): # Train model with epoch_total \n",
    "    print('Epoch:', epoch+1)\n",
    "    model.fit(Xtrain, Ytrain, batch_size=batch_size, epochs=1,\n",
    "              shuffle=True) # Fit model for 1 iteration.\n",
    "    \n",
    "    start_index = random.randint(0, len(midis_array)- max_len - 1)\n",
    "    \n",
    "    generated_midi = midis_array[start_index: start_index + max_len]\n",
    "        \n",
    "    if ((epoch%3) == 0):\n",
    "        model.save_weights('my_model_weights.h5')\n",
    "        #saves the model in case you want to continue training later and as checkpoints\n",
    "        model.save('model_data')\n",
    "\n",
    "        for temperature in [1.2]:\n",
    "            print('------ temperature:', temperature)\n",
    "\n",
    "            for i in range(480):\n",
    "                samples = generated_midi[i:]\n",
    "                expanded_samples = np.expand_dims(samples, axis=0)\n",
    "                preds = model.predict(expanded_samples, verbose=0)[0]\n",
    "                preds = np.asarray(preds).astype('float64')\n",
    "\n",
    "                next_array = sample(preds, temperature)\n",
    "              \n",
    "                midi_list = []\n",
    "                midi_list.append(generated_midi)\n",
    "                midi_list.append(next_array)\n",
    "                generated_midi = np.vstack(midi_list)\n",
    "              \n",
    "\n",
    "            generated_midi_final = np.transpose(generated_midi,(1,0))\n",
    "            output_notes = matrix_to_midi(generated_midi_final, random=1)\n",
    "            midi_stream = music21.stream.Stream(output_notes)\n",
    "            midi_file_name = ('lstm_out_{}_{}.mid'.format(epoch, temperature))\n",
    "            midi_stream.write('midi', fp=midi_file_name)\n",
    "            parsed = music21.converter.parse(midi_file_name)\n",
    "            for part in parsed.parts:\n",
    "                part.insert(0, music21.instrument.Piano())\n",
    "                parsed.write('midi', fp=midi_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save weights manually after training; use this only to generate samples\n",
    "\n",
    "model.save_weights('final_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model manually in case you want to continue training later and as checkpoints\n",
    "model.save('final_model_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to use a pre-defined or previously saved set of weights, load them with this and then generate samples below\n",
    "name_h5 = ''\n",
    "model.load_weights(name_h5) # load model's weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ temperature: 0.7\n",
      "How many rows for non-start note at beginning: 20\n",
      "How many rows for non-start note at end: 0\n",
      "128 600\n",
      "------ temperature: 2.7\n",
      "How many rows for non-start note at beginning: 20\n",
      "How many rows for non-start note at end: 0\n",
      "128 600\n"
     ]
    }
   ],
   "source": [
    "#after training the model, take some samples :O\n",
    "\n",
    "start_index = random.randint(0, len(midis_array)- max_len - 1)\n",
    "    \n",
    "generated_midi = midis_array[start_index: start_index + max_len]\n",
    "\n",
    "for temperature in [0.7, 2.7]:\n",
    "        print('------ temperature:', temperature)\n",
    "        generated_midi = midis_array[start_index: start_index + max_len]\n",
    "        \n",
    "        #this just decides the length of the output file samples\n",
    "        for i in range(600):\n",
    "            samples = generated_midi[i:]\n",
    "            expanded_samples = np.expand_dims(samples, axis=0)\n",
    "            preds = model.predict(expanded_samples, verbose=0)[0]\n",
    "            preds = np.asarray(preds).astype('float64')\n",
    "\n",
    "            next_array = sample(preds, temperature)\n",
    "           \n",
    "            midi_list = []\n",
    "            midi_list.append(generated_midi)\n",
    "            midi_list.append(next_array)\n",
    "            generated_midi = np.vstack(midi_list)\n",
    "            \n",
    "\n",
    "        generated_midi_final = np.transpose(generated_midi,(1,0))\n",
    "        output_notes = matrix_to_midi(generated_midi_final, random=1)\n",
    "        midi_stream = music21.stream.Stream(output_notes)\n",
    "        midi_file_name = ('lstm_out_{}.mid'.format(temperature))\n",
    "        midi_stream.write('midi', fp=midi_file_name)\n",
    "        parsed = music21.converter.parse(midi_file_name)\n",
    "        for part in parsed.parts:\n",
    "            part.insert(0, music21.instrument.Piano())\n",
    "        parsed.write('midi', fp=midi_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see values\n",
    "\n",
    "import bottleneck \n",
    "z = -bottleneck.partition(-preds, 20)[:20]\n",
    "print (z)\n",
    "print ('max:', np.max(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for instrument in music21.instrument.Piano():\n",
    "    print(instrument)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
